# AI æœåŠ¡å¼€å‘æŒ‡å—

> ç»Ÿä¸€çš„ AI æœåŠ¡é›†æˆå’Œå¼€å‘æ–‡æ¡£
> 
> æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0
> åˆ›å»ºæ—¶é—´ï¼š2026-02-20
> æœ€åæ›´æ–°ï¼š2026-02-20

---

## ğŸ“‹ æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£æ˜¯ AI æœåŠ¡å¼€å‘çš„**ç»Ÿä¸€å…¥å£å’Œæƒå¨æŒ‡å—**ï¼Œæ•´åˆäº†ï¼š
- å…è´¹å’Œä»˜è´¹ AI API èµ„æº
- LiteLLM ç»Ÿä¸€æ¥å£é›†æˆæ–¹æ¡ˆ
- å¤šæä¾›å•†æ¥å…¥æŒ‡å—
- æœ€ä½³å®è·µå’Œä»£ç ç¤ºä¾‹

**ç›®æ ‡è¯»è€…**ï¼šAI åŠ©æ‰‹ã€å¼€å‘è€…

**ä½¿ç”¨æ–¹å¼**ï¼š
1. AI åŠ©æ‰‹é˜…è¯»æœ¬æ–‡æ¡£äº†è§£ AI æœåŠ¡æ¶æ„å’Œå¼€å‘è§„èŒƒ
2. æŒ‰ç…§æœ¬æ–‡æ¡£å®ç° AI åŠŸèƒ½
3. å®Œæˆä»»åŠ¡ååœ¨"å¼€å‘è¿›åº¦"éƒ¨åˆ†è®°å½•
4. ä¸‹ä¸€ä¸ª AI åŠ©æ‰‹å¯ä»¥ä»è¿›åº¦è®°å½•ç»§ç»­å·¥ä½œ

---

## ä¸€ã€é¡¹ç›®èƒŒæ™¯

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦ç»Ÿä¸€ AI æ¥å£ï¼Ÿ

**é—®é¢˜**ï¼š
- ä¸åŒ AI æä¾›å•† API æ ¼å¼ä¸ç»Ÿä¸€
- åˆ‡æ¢æä¾›å•†éœ€è¦å¤§é‡ä»£ç ä¿®æ”¹
- å…è´¹é¢åº¦åˆ†æ•£ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨
- ç¼ºå°‘ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

**è§£å†³æ–¹æ¡ˆ**ï¼š
- é‡‡ç”¨ **LiteLLM ç»Ÿä¸€æ¥å£**æ¨¡å¼
- å°è£…ç»Ÿä¸€çš„ AI æœåŠ¡å±‚
- æ”¯æŒå¤šæä¾›å•†åŠ¨æ€åˆ‡æ¢
- å®ç°æ™ºèƒ½é™çº§å’Œé‡è¯•

### 1.2 å‚è€ƒé¡¹ç›®

#### TrendRadar (46k+ stars)
- **GitHub**: https://github.com/sansan0/TrendRadar
- **å€Ÿé‰´ç‚¹**ï¼šLiteLLM ç»Ÿä¸€æ¥å£ã€AI åˆ†ææç¤ºè¯è®¾è®¡
- **è¯¦ç»†åˆ†æ**: [hot-topics-reference.md](./hot-topics-reference.md)

#### Free LLM API Resources (11k+ stars)
- **GitHub**: https://github.com/cheahjs/free-llm-api-resources
- **å€Ÿé‰´ç‚¹**ï¼šå…è´¹ AI èµ„æºæ±‡æ€»ã€æä¾›å•†é™åˆ¶ä¿¡æ¯
- **æ ¸å¿ƒä»·å€¼**ï¼šæä¾› 20+ ä¸ªå…è´¹ AI API èµ„æº

---

## äºŒã€å…è´¹ AI èµ„æºæ±‡æ€»

> æ•°æ®æ¥æºï¼š[free-llm-api-resources](https://github.com/cheahjs/free-llm-api-resources)
> 
> æ›´æ–°æ—¶é—´ï¼š2026-02-20

### 2.1 å®Œå…¨å…è´¹æä¾›å•†

#### 2.1.1 OpenRouter â­ æ¨è

**å®˜ç½‘**: https://openrouter.ai

**é™åˆ¶**ï¼š
- 20 è¯·æ±‚/åˆ†é’Ÿ
- 50 è¯·æ±‚/å¤©
- å……å€¼ $10 å¯æå‡è‡³ 1000 è¯·æ±‚/å¤©

**å…è´¹æ¨¡å‹**ï¼š
```
- google/gemma-3-12b-it:free
- google/gemma-3-27b-it:free
- google/gemma-3-4b-it:free
- meta-llama/llama-3.2-3b-instruct:free
- meta-llama/llama-3.3-70b-instruct:free
- mistralai/mistral-small-3.1-24b-instruct:free
- deepseek/deepseek-r1-0528:free
- qwen/qwen-2.5-72b-instruct:free
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹
```bash
curl https://openrouter.ai/api/v1/chat/completions \
  -H "Authorization: Bearer $OPENROUTER_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta-llama/llama-3.3-70b-instruct:free",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… æµ‹è¯•å’Œå¼€å‘
- âœ… ä½é¢‘è°ƒç”¨
- âœ… å¤šæ¨¡å‹å¯¹æ¯”

#### 2.1.2 Google AI Studio â­ æ¨è

**å®˜ç½‘**: https://aistudio.google.com

**é™åˆ¶**ï¼š
| æ¨¡å‹ | Tokens/åˆ†é’Ÿ | è¯·æ±‚/å¤© | è¯·æ±‚/åˆ†é’Ÿ |
|------|------------|--------|----------|
| Gemini 3 Flash | 250,000 | 20 | 5 |
| Gemini 2.5 Flash | 250,000 | 20 | 5 |
| Gemma 3 27B | 15,000 | 14,400 | 30 |
| Gemma 3 12B | 15,000 | 14,400 | 30 |

**å…è´¹æ¨¡å‹**ï¼š
```
- gemini-3-flash
- gemini-2.5-flash
- gemini-2.5-flash-lite
- gemma-3-27b-it
- gemma-3-12b-it
- gemma-3-4b-it
- gemma-3-1b-it
```

**API æ ¼å¼**ï¼šè‡ªå®šä¹‰ï¼ˆä½†å…¼å®¹ OpenAIï¼‰
```bash
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=$GOOGLE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{"parts": [{"text": "Hello"}]}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… é«˜é¢‘è°ƒç”¨ï¼ˆGemma ç³»åˆ—ï¼‰
- âœ… é•¿æ–‡æœ¬å¤„ç†ï¼ˆGemini Flashï¼‰
- âš ï¸ æ³¨æ„ï¼šæ•°æ®å¯èƒ½ç”¨äºè®­ç»ƒï¼ˆéæ¬§ç›Ÿåœ°åŒºï¼‰

#### 2.1.3 NVIDIA NIM

**å®˜ç½‘**: https://build.nvidia.com/explore/discover

**é™åˆ¶**ï¼š5000 tokens/åˆ†é’Ÿ

**å…è´¹æ¨¡å‹**ï¼š
```
- meta/llama-3.1-405b-instruct
- meta/llama-3.1-70b-instruct
- meta/llama-3.1-8b-instruct
- meta/llama-3.2-11b-vision-instruct
- meta/llama-3.2-3b-instruct
- meta/llama-3.2-1b-instruct
- mistralai/mistral-large
- mistralai/mixtral-8x7b-instruct
- google/gemma-2-27b-it
- google/gemma-2-9b-it
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹
```bash
curl https://integrate.api.nvidia.com/v1/chat/completions \
  -H "Authorization: Bearer $NVIDIA_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "meta/llama-3.1-405b-instruct",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… å¤§æ¨¡å‹æ¨ç†ï¼ˆLlama 405Bï¼‰
- âœ… è§†è§‰æ¨¡å‹
- âœ… é«˜è´¨é‡è¾“å‡º

#### 2.1.4 Groq âš¡ æœ€å¿«æ¨ç†

**å®˜ç½‘**: https://console.groq.com

**é™åˆ¶**ï¼š
- 30 è¯·æ±‚/åˆ†é’Ÿï¼ˆå…è´¹ï¼‰
- 7000 tokens/åˆ†é’Ÿ

**å…è´¹æ¨¡å‹**ï¼š
```
- llama-3.3-70b-versatile
- llama-3.1-8b-instant
- mixtral-8x7b-32768
- gemma2-9b-it
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹
```bash
curl https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.3-70b-versatile",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… å®æ—¶å¯¹è¯
- âœ… å¿«é€Ÿå“åº”
- âœ… æµå¼è¾“å‡º

#### 2.1.5 Mistral

**å®˜ç½‘**: https://console.mistral.ai

**é™åˆ¶**ï¼š
- 1 è¯·æ±‚/ç§’
- 500,000 tokens/æœˆ

**å…è´¹æ¨¡å‹**ï¼š
```
- mistral-small-latest
- codestral-latest
- mistral-7b-instruct
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹
```bash
curl https://api.mistral.ai/v1/chat/completions \
  -H "Authorization: Bearer $MISTRAL_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mistral-small-latest",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… ä»£ç ç”Ÿæˆï¼ˆCodestralï¼‰
- âœ… æ¬§æ´²åˆè§„éœ€æ±‚

#### 2.1.6 Cloudflare Workers AI

**å®˜ç½‘**: https://developers.cloudflare.com/workers-ai

**é™åˆ¶**ï¼š10,000 neurons/å¤©

**å…è´¹æ¨¡å‹**ï¼š
```
- @cf/meta/llama-3.1-8b-instruct
- @cf/meta/llama-3.2-3b-instruct
- @cf/mistral/mistral-7b-instruct
- @cf/google/gemma-3-12b-it
- @cf/qwen/qwen-2.5-72b-instruct
- @cf/deepseek/r1-distill-qwen-32b
```

**API æ ¼å¼**ï¼šè‡ªå®šä¹‰
```bash
curl https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai/run/@cf/meta/llama-3.1-8b-instruct \
  -H "Authorization: Bearer $CF_API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… è¾¹ç¼˜è®¡ç®—
- âœ… Cloudflare ç”Ÿæ€é›†æˆ

#### 2.1.7 GitHub Models

**å®˜ç½‘**: https://github.com/marketplace/models

**é™åˆ¶**ï¼š
- ä½é€Ÿç‡é™åˆ¶ï¼ˆå…·ä½“æœªå…¬å¼€ï¼‰
- éœ€ GitHub è´¦å·

**å…è´¹æ¨¡å‹**ï¼š
```
- gpt-4o
- gpt-4o-mini
- o1-preview
- o1-mini
- phi-3.5-mini
- phi-3-medium
- meta-llama-3.1-405b-instruct
- meta-llama-3.1-70b-instruct
- mistral-large
- cohere-command-r
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹
```bash
curl https://models.inference.ai.azure.com/chat/completions \
  -H "Authorization: Bearer $GITHUB_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… GitHub ç”Ÿæ€é›†æˆ
- âœ… å¼€å‘è€…å‹å¥½

#### 2.1.8 Cohere

**å®˜ç½‘**: https://cohere.com

**é™åˆ¶**ï¼š
- 1000 æ¬¡/æœˆï¼ˆå…è´¹è¯•ç”¨ï¼‰
- éœ€ä¿¡ç”¨å¡éªŒè¯

**å…è´¹æ¨¡å‹**ï¼š
```
- command
- command-light
- command-r
- command-r-plus
```

**API æ ¼å¼**ï¼šè‡ªå®šä¹‰
```bash
curl https://api.cohere.ai/v1/chat \
  -H "Authorization: Bearer $COHERE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "command-r-plus",
    "message": "Hello"
  }'
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… ä¼ä¸šçº§åº”ç”¨
- âœ… RAG åº”ç”¨

### 2.2 è¯•ç”¨é¢åº¦æä¾›å•†

#### 2.2.1 Fireworks AI

**å®˜ç½‘**: https://fireworks.ai

**è¯•ç”¨é¢åº¦**ï¼š$1 å…è´¹é¢åº¦

**æ¨¡å‹**ï¼š
```
- llama-3.1-405b-instruct
- llama-3.1-70b-instruct
- qwen2.5-72b-instruct
- mixtral-8x7b-instruct
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹

#### 2.2.2 Together AI

**å®˜ç½‘**: https://together.ai

**è¯•ç”¨é¢åº¦**ï¼š$1 å…è´¹é¢åº¦

**æ¨¡å‹**ï¼š
```
- meta-llama/Llama-3-70b-chat-hf
- mistralai/Mixtral-8x7B-Instruct-v0.1
- togethercomputer/CodeLlama-34b-Instruct
```

**API æ ¼å¼**ï¼šOpenAI å…¼å®¹

#### 2.2.3 å…¶ä»–è¯•ç”¨æä¾›å•†

| æä¾›å•† | è¯•ç”¨é¢åº¦ | ç‰¹ç‚¹ |
|--------|---------|------|
| Baseten | $10 | è‡ªå®šä¹‰æ¨¡å‹éƒ¨ç½² |
| Nebius | $10 | äº‘è®¡ç®—å¹³å° |
| Novita | $5 | å¤šæ¨¡å‹æ”¯æŒ |
| AI21 | $10 | Jurassic ç³»åˆ— |
| Upstage | $10 | éŸ©å›½æ¨¡å‹ |
| NLP Cloud | $10 | ä¼ä¸šçº§ |
| Modal | $10 | æ— æœåŠ¡å™¨éƒ¨ç½² |
| Hyperbolic | $10 | å»ä¸­å¿ƒåŒ– |
| SambaNova | $10 | ä¼ä¸š AI |

---

## ä¸‰ã€LiteLLM ç»Ÿä¸€æ¥å£æ–¹æ¡ˆ

### 3.1 LiteLLM ç®€ä»‹

**LiteLLM** æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ LLM æ¥å£åº“ï¼Œæä¾›ï¼š
- ç»Ÿä¸€çš„ API è°ƒç”¨æ ¼å¼ï¼ˆOpenAI æ ¼å¼ï¼‰
- æ”¯æŒ 100+ AI æä¾›å•†
- è‡ªåŠ¨é‡è¯•å’Œé™çº§
- æˆæœ¬è¿½è¸ª
- ç¼“å­˜æ”¯æŒ

**GitHub**: https://github.com/BerriAI/litellm

### 3.2 ä¸ºä»€ä¹ˆé€‰æ‹© LiteLLM æ¨¡å¼ï¼Ÿ

| ç‰¹æ€§ | ç›´æ¥è°ƒç”¨ | LiteLLM æ¨¡å¼ |
|------|---------|-------------|
| API æ ¼å¼ | æ¯ä¸ªæä¾›å•†ä¸åŒ | ç»Ÿä¸€ OpenAI æ ¼å¼ |
| åˆ‡æ¢æä¾›å•† | éœ€ä¿®æ”¹ä»£ç  | ä»…æ”¹é…ç½® |
| é”™è¯¯å¤„ç† | æ‰‹åŠ¨å®ç° | è‡ªåŠ¨å¤„ç† |
| é‡è¯•æœºåˆ¶ | æ‰‹åŠ¨å®ç° | å†…ç½®æ”¯æŒ |
| æˆæœ¬è¿½è¸ª | æ‰‹åŠ¨å®ç° | è‡ªåŠ¨è®°å½• |
| å…è´¹é¢åº¦åˆ©ç”¨ | éš¾ä»¥ç®¡ç† | ç»Ÿä¸€ç®¡ç† |

### 3.3 Go å®ç°æ–¹æ¡ˆ

ç”±äºé¡¹ç›®ä½¿ç”¨ Go è¯­è¨€ï¼Œæˆ‘ä»¬éœ€è¦å®ç°ç±»ä¼¼ LiteLLM çš„ç»Ÿä¸€æ¥å£ã€‚

#### 3.3.1 æ ¸å¿ƒæ¥å£è®¾è®¡

```go
// ai/provider/interface.go

package provider

import "context"

// GenerateOptions ç”Ÿæˆé€‰é¡¹
type GenerateOptions struct {
    Model       string
    Messages    []Message
    Temperature float64
    MaxTokens   int
    Stream      bool
}

// Message æ¶ˆæ¯
type Message struct {
    Role    Role
    Content string
}

// Role è§’è‰²
type Role string

const (
    RoleSystem Role = "system"
    RoleUser   Role = "user"
    RoleAssistant Role = "assistant"
)

// GenerateResult ç”Ÿæˆç»“æœ
type GenerateResult struct {
    Content      string
    TokensUsed   int
    Model        string
    Provider     string
    FinishReason string
}

// Provider AI æä¾›å•†æ¥å£
type Provider interface {
    // Name æä¾›å•†åç§°
    Name() string
    
    // Generate ç”Ÿæˆå†…å®¹
    Generate(ctx context.Context, opts *GenerateOptions) (*GenerateResult, error)
    
    // GenerateStream æµå¼ç”Ÿæˆ
    GenerateStream(ctx context.Context, opts *GenerateOptions) (<-chan string, error)
    
    // ListModels åˆ—å‡ºå¯ç”¨æ¨¡å‹
    ListModels() []string
    
    // IsAvailable æ£€æŸ¥æ˜¯å¦å¯ç”¨
    IsAvailable() bool
}
```

#### 3.3.2 OpenAI å…¼å®¹æä¾›å•†å®ç°

```go
// ai/provider/openai_compatible.go

package provider

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
)

// OpenAICompatibleProvider OpenAI å…¼å®¹æä¾›å•†
type OpenAICompatibleProvider struct {
    name     string
    apiBase  string
    apiKey   string
    models   []string
    client   *http.Client
}

func NewOpenAICompatibleProvider(name, apiBase, apiKey string, models []string) *OpenAICompatibleProvider {
    return &OpenAICompatibleProvider{
        name:    name,
        apiBase: apiBase,
        apiKey:  apiKey,
        models:  models,
        client:  &http.Client{},
    }
}

func (p *OpenAICompatibleProvider) Name() string {
    return p.name
}

func (p *OpenAICompatibleProvider) Generate(ctx context.Context, opts *GenerateOptions) (*GenerateResult, error) {
    // æ„å»ºè¯·æ±‚
    reqBody := map[string]interface{}{
        "model": opts.Model,
        "messages": opts.Messages,
    }
    
    if opts.Temperature > 0 {
        reqBody["temperature"] = opts.Temperature
    }
    if opts.MaxTokens > 0 {
        reqBody["max_tokens"] = opts.MaxTokens
    }
    
    body, err := json.Marshal(reqBody)
    if err != nil {
        return nil, fmt.Errorf("marshal request: %w", err)
    }
    
    // å‘é€è¯·æ±‚
    url := fmt.Sprintf("%s/chat/completions", p.apiBase)
    req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewReader(body))
    if err != nil {
        return nil, fmt.Errorf("create request: %w", err)
    }
    
    req.Header.Set("Authorization", "Bearer "+p.apiKey)
    req.Header.Set("Content-Type", "application/json")
    
    resp, err := p.client.Do(req)
    if err != nil {
        return nil, fmt.Errorf("send request: %w", err)
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        bodyBytes, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("API error: %s - %s", resp.Status, string(bodyBytes))
    }
    
    // è§£æå“åº”
    var result struct {
        Choices []struct {
            Message struct {
                Content string `json:"content"`
            } `json:"message"`
            FinishReason string `json:"finish_reason"`
        } `json:"choices"`
        Usage struct {
            TotalTokens int `json:"total_tokens"`
        } `json:"usage"`
        Model string `json:"model"`
    }
    
    if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
        return nil, fmt.Errorf("decode response: %w", err)
    }
    
    if len(result.Choices) == 0 {
        return nil, fmt.Errorf("no choices in response")
    }
    
    return &GenerateResult{
        Content:      result.Choices[0].Message.Content,
        TokensUsed:   result.Usage.TotalTokens,
        Model:        result.Model,
        Provider:     p.name,
        FinishReason: result.Choices[0].FinishReason,
    }, nil
}

func (p *OpenAICompatibleProvider) ListModels() []string {
    return p.models
}

func (p *OpenAICompatibleProvider) IsAvailable() bool {
    return p.apiKey != ""
}
```

#### 3.3.3 æä¾›å•†æ³¨å†Œ

```go
// ai/provider/registry.go

package provider

import (
    "os"
    "sync"
)

// Registry æä¾›å•†æ³¨å†Œè¡¨
type Registry struct {
    providers map[string]Provider
    priority  []string // ä¼˜å…ˆçº§é¡ºåº
    mu        sync.RWMutex
}

func NewRegistry() *Registry {
    return &Registry{
        providers: make(map[string]Provider),
        priority:  []string{},
    }
}

// Register æ³¨å†Œæä¾›å•†
func (r *Registry) Register(p Provider) {
    r.mu.Lock()
    defer r.mu.Unlock()
    
    r.providers[p.Name()] = p
    r.priority = append(r.priority, p.Name())
}

// Get è·å–æä¾›å•†
func (r *Registry) Get(name string) (Provider, bool) {
    r.mu.RLock()
    defer r.mu.RUnlock()
    
    p, ok := r.providers[name]
    return p, ok
}

// GetAvailable è·å–å¯ç”¨çš„æä¾›å•†ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
func (r *Registry) GetAvailable() []Provider {
    r.mu.RLock()
    defer r.mu.RUnlock()
    
    var available []Provider
    for _, name := range r.priority {
        if p, ok := r.providers[name]; ok && p.IsAvailable() {
            available = append(available, p)
        }
    }
    return available
}

// InitFromEnv ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–
func (r *Registry) InitFromEnv() {
    // OpenRouter
    if key := os.Getenv("OPENROUTER_API_KEY"); key != "" {
        r.Register(NewOpenAICompatibleProvider(
            "openrouter",
            "https://openrouter.ai/api/v1",
            key,
            []string{
                "meta-llama/llama-3.3-70b-instruct:free",
                "google/gemma-3-27b-it:free",
                "deepseek/deepseek-r1-0528:free",
            },
        ))
    }
    
    // Groq
    if key := os.Getenv("GROQ_API_KEY"); key != "" {
        r.Register(NewOpenAICompatibleProvider(
            "groq",
            "https://api.groq.com/openai/v1",
            key,
            []string{
                "llama-3.3-70b-versatile",
                "llama-3.1-8b-instant",
                "mixtral-8x7b-32768",
            },
        ))
    }
    
    // NVIDIA NIM
    if key := os.Getenv("NVIDIA_API_KEY"); key != "" {
        r.Register(NewOpenAICompatibleProvider(
            "nvidia",
            "https://integrate.api.nvidia.com/v1",
            key,
            []string{
                "meta/llama-3.1-405b-instruct",
                "meta/llama-3.1-70b-instruct",
            },
        ))
    }
    
    // Mistral
    if key := os.Getenv("MISTRAL_API_KEY"); key != "" {
        r.Register(NewOpenAICompatibleProvider(
            "mistral",
            "https://api.mistral.ai/v1",
            key,
            []string{
                "mistral-small-latest",
                "codestral-latest",
            },
        ))
    }
    
    // Google AI Studio
    if key := os.Getenv("GOOGLE_API_KEY"); key != "" {
        r.Register(NewGoogleAIProvider(key))
    }
    
    // DeepSeek
    if key := os.Getenv("DEEPSEEK_API_KEY"); key != "" {
        r.Register(NewOpenAICompatibleProvider(
            "deepseek",
            "https://api.deepseek.com/v1",
            key,
            []string{
                "deepseek-chat",
                "deepseek-coder",
            },
        ))
    }
}
```

#### 3.3.4 ç»Ÿä¸€æœåŠ¡å±‚

```go
// ai/service.go

package ai

import (
    "context"
    "fmt"
    
    "publisher-core/ai/provider"
)

// Service AI æœåŠ¡
type Service struct {
    registry *provider.Registry
    config   *Config
}

type Config struct {
    DefaultProvider string
    DefaultModel    string
    MaxRetries      int
    FallbackEnabled bool
}

func NewService(registry *provider.Registry, config *Config) *Service {
    return &Service{
        registry: registry,
        config:   config,
    }
}

// Generate ç”Ÿæˆå†…å®¹ï¼ˆè‡ªåŠ¨é€‰æ‹©æä¾›å•†ï¼‰
func (s *Service) Generate(ctx context.Context, opts *provider.GenerateOptions) (*provider.GenerateResult, error) {
    // å¦‚æœæŒ‡å®šäº†æä¾›å•†ï¼Œç›´æ¥ä½¿ç”¨
    if opts.Model != "" && s.config.DefaultProvider != "" {
        p, ok := s.registry.Get(s.config.DefaultProvider)
        if !ok {
            return nil, fmt.Errorf("provider %s not found", s.config.DefaultProvider)
        }
        return s.generateWithRetry(ctx, p, opts)
    }
    
    // å¦åˆ™æŒ‰ä¼˜å…ˆçº§å°è¯•
    providers := s.registry.GetAvailable()
    if len(providers) == 0 {
        return nil, fmt.Errorf("no available providers")
    }
    
    var lastErr error
    for _, p := range providers {
        result, err := s.generateWithRetry(ctx, p, opts)
        if err == nil {
            return result, nil
        }
        lastErr = err
        
        // å¦‚æœä¸å¯ç”¨é™çº§ï¼Œç›´æ¥è¿”å›é”™è¯¯
        if !s.config.FallbackEnabled {
            break
        }
    }
    
    return nil, fmt.Errorf("all providers failed: %w", lastErr)
}

// generateWithRetry å¸¦é‡è¯•çš„ç”Ÿæˆ
func (s *Service) generateWithRetry(ctx context.Context, p provider.Provider, opts *provider.GenerateOptions) (*provider.GenerateResult, error) {
    var lastErr error
    
    for i := 0; i <= s.config.MaxRetries; i++ {
        result, err := p.Generate(ctx, opts)
        if err == nil {
            return result, nil
        }
        
        lastErr = err
        
        // æ£€æŸ¥æ˜¯å¦å¯é‡è¯•
        if !s.isRetryableError(err) {
            break
        }
    }
    
    return nil, lastErr
}

// isRetryableError åˆ¤æ–­æ˜¯å¦å¯é‡è¯•
func (s *Service) isRetryableError(err error) bool {
    // ç½‘ç»œé”™è¯¯ã€è¶…æ—¶ã€429 ç­‰å¯é‡è¯•
    // å…¶ä»–é”™è¯¯ä¸é‡è¯•
    return true // ç®€åŒ–å®ç°
}
```

### 3.4 é…ç½®ç®¡ç†

```yaml
# config/ai.yaml

ai:
  # é»˜è®¤æä¾›å•†
  default_provider: "openrouter"
  
  # é»˜è®¤æ¨¡å‹
  default_model: "meta-llama/llama-3.3-70b-instruct:free"
  
  # é‡è¯•æ¬¡æ•°
  max_retries: 3
  
  # å¯ç”¨é™çº§
  fallback_enabled: true
  
  # æä¾›å•†ä¼˜å…ˆçº§
  priority:
    - openrouter  # å…è´¹ï¼Œå¤šæ¨¡å‹
    - groq        # æœ€å¿«
    - nvidia      # å¤§æ¨¡å‹
    - mistral     # ä»£ç 
    - google      # Gemini
    - deepseek    # å¤‡ç”¨

# æä¾›å•†é…ç½®
providers:
  openrouter:
    api_key: "${OPENROUTER_API_KEY}"
    models:
      - "meta-llama/llama-3.3-70b-instruct:free"
      - "google/gemma-3-27b-it:free"
      - "deepseek/deepseek-r1-0528:free"
  
  groq:
    api_key: "${GROQ_API_KEY}"
    models:
      - "llama-3.3-70b-versatile"
      - "llama-3.1-8b-instant"
  
  nvidia:
    api_key: "${NVIDIA_API_KEY}"
    models:
      - "meta/llama-3.1-405b-instruct"
      - "meta/llama-3.1-70b-instruct"
```

---

## å››ã€å¼€å‘è¿›åº¦è®°å½•

> **é‡è¦**ï¼šå®Œæˆä»»åŠ¡ååœ¨æ­¤è®°å½•ï¼Œä¸‹ä¸€ä¸ª AI åŠ©æ‰‹å¯ä»¥ç»§ç»­

### 4.1 å·²å®Œæˆä»»åŠ¡

#### âœ… 2026-02-20: æ–‡æ¡£åˆ›å»º
- **ä»»åŠ¡**ï¼šåˆ›å»ºç»Ÿä¸€çš„ AI æœåŠ¡å¼€å‘æŒ‡å—
- **å®Œæˆå†…å®¹**ï¼š
  - æ•´åˆ free-llm-api-resources é¡¹ç›®åˆ†æ
  - æ•´åˆ TrendRadar LiteLLM æ–¹æ¡ˆ
  - åˆ›å»ºç»Ÿä¸€çš„æ¥å£è®¾è®¡
  - æä¾›å®Œæ•´çš„ä»£ç ç¤ºä¾‹
- **è´Ÿè´£äºº**ï¼šAI åŠ©æ‰‹
- **çŠ¶æ€**ï¼šâœ… å®Œæˆ
- **äº§å‡ºæ–‡æ¡£**ï¼š
  - `docs/ai-service-development-guide.md`ï¼ˆæœ¬æ–‡æ¡£ï¼‰
  - `docs/hot-topics-reference.md`
  - `docs/hot-topics-roadmap.md`

### 4.2 å¾…å®Œæˆä»»åŠ¡

#### ğŸ“‹ Phase 1: åŸºç¡€æ¡†æ¶å®ç°
- [ ] å®ç° Provider æ¥å£
- [ ] å®ç° OpenAI å…¼å®¹æä¾›å•†
- [ ] å®ç°æä¾›å•†æ³¨å†Œè¡¨
- [ ] å®ç°ç»Ÿä¸€æœåŠ¡å±‚
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•

**é¢„è®¡æ—¶é—´**ï¼š1 å‘¨
**ä¼˜å…ˆçº§**ï¼šé«˜
**ä¾èµ–**ï¼šæ— 

#### ğŸ“‹ Phase 2: æä¾›å•†é›†æˆ
- [ ] é›†æˆ OpenRouter
- [ ] é›†æˆ Groq
- [ ] é›†æˆ NVIDIA NIM
- [ ] é›†æˆ Mistral
- [ ] é›†æˆ Google AI Studio
- [ ] é›†æˆ DeepSeek

**é¢„è®¡æ—¶é—´**ï¼š1 å‘¨
**ä¼˜å…ˆçº§**ï¼šé«˜
**ä¾èµ–**ï¼šPhase 1 å®Œæˆ

#### ğŸ“‹ Phase 3: é«˜çº§åŠŸèƒ½
- [ ] å®ç°æµå¼è¾“å‡º
- [ ] å®ç°æ™ºèƒ½é™çº§
- [ ] å®ç°æˆæœ¬è¿½è¸ª
- [ ] å®ç°ç¼“å­˜æœºåˆ¶
- [ ] å®ç°é€Ÿç‡é™åˆ¶

**é¢„è®¡æ—¶é—´**ï¼š1 å‘¨
**ä¼˜å…ˆçº§**ï¼šä¸­
**ä¾èµ–**ï¼šPhase 2 å®Œæˆ

#### ğŸ“‹ Phase 4: çƒ­ç‚¹ç›‘æ§é›†æˆ
- [ ] é›†æˆåˆ°çƒ­ç‚¹ç›‘æ§ AI åˆ†æ
- [ ] ä¼˜åŒ– AI åˆ†ææç¤ºè¯
- [ ] å®ç°å¤šæ¨¡å‹å¯¹æ¯”
- [ ] å®ç°åˆ†æç»“æœç¼“å­˜

**é¢„è®¡æ—¶é—´**ï¼š1 å‘¨
**ä¼˜å…ˆçº§**ï¼šä¸­
**ä¾èµ–**ï¼šPhase 3 å®Œæˆ

---

## äº”ã€æœ€ä½³å®è·µ

### 5.1 æä¾›å•†é€‰æ‹©ç­–ç•¥

```go
// æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æä¾›å•†
func SelectProvider(taskType string) string {
    switch taskType {
    case "code_generation":
        return "mistral"  // Codestral
    case "fast_response":
        return "groq"     // æœ€å¿«
    case "large_model":
        return "nvidia"   // Llama 405B
    case "free_tier":
        return "openrouter" // å…è´¹
    default:
        return "openrouter" // é»˜è®¤
    }
}
```

### 5.2 é”™è¯¯å¤„ç†

```go
func (s *Service) Generate(ctx context.Context, opts *provider.GenerateOptions) (*provider.GenerateResult, error) {
    result, err := s.generateWithRetry(ctx, p, opts)
    if err != nil {
        // è®°å½•é”™è¯¯
        log.Errorf("AI generation failed: %v", err)
        
        // é™çº§åˆ°å…¶ä»–æä¾›å•†
        if s.config.FallbackEnabled {
            return s.fallback(ctx, opts)
        }
        
        return nil, err
    }
    return result, nil
}
```

### 5.3 æˆæœ¬ä¼˜åŒ–

```go
// ä½¿ç”¨å…è´¹é¢åº¦ä¼˜å…ˆ
func (s *Service) selectFreeProvider() Provider {
    providers := s.registry.GetAvailable()
    
    // ä¼˜å…ˆé€‰æ‹©å…è´¹æ¨¡å‹
    for _, p := range providers {
        if strings.Contains(p.Name(), "free") {
            return p
        }
    }
    
    // å¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„
    if len(providers) > 0 {
        return providers[0]
    }
    
    return nil
}
```

### 5.4 é€Ÿç‡é™åˆ¶

```go
type RateLimiter struct {
    requests map[string]*rate.Limiter
    mu       sync.RWMutex
}

func (l *RateLimiter) Wait(ctx context.Context, provider string) error {
    l.mu.RLock()
    limiter, ok := l.requests[provider]
    l.mu.RUnlock()
    
    if !ok {
        return nil
    }
    
    return limiter.Wait(ctx)
}
```

---

## å…­ã€å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è·å–å…è´¹ API Keyï¼Ÿ

**A**: æŒ‰ä»¥ä¸‹æ­¥éª¤ï¼š
1. OpenRouter: https://openrouter.ai/keys
2. Groq: https://console.groq.com/keys
3. NVIDIA: https://build.nvidia.com/api-key
4. Mistral: https://console.mistral.ai/api-keys
5. Google AI: https://aistudio.google.com/apikey

### Q2: å…è´¹é¢åº¦ç”¨å®Œäº†æ€ä¹ˆåŠï¼Ÿ

**A**: 
1. åˆ‡æ¢åˆ°å…¶ä»–å…è´¹æä¾›å•†
2. ä½¿ç”¨è¯•ç”¨é¢åº¦æä¾›å•†
3. è€ƒè™‘ä»˜è´¹ï¼ˆOpenRouter $10 å¯ç”¨å¾ˆä¹…ï¼‰

### Q3: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Ÿ

**A**: 
- **ä»£ç ç”Ÿæˆ**: Codestral, DeepSeek Coder
- **å¿«é€Ÿå“åº”**: Groq (Llama 3.3 70B)
- **é«˜è´¨é‡è¾“å‡º**: NVIDIA (Llama 405B)
- **é•¿æ–‡æœ¬**: Google Gemini Flash
- **å…è´¹æµ‹è¯•**: OpenRouter å…è´¹æ¨¡å‹

### Q4: å¦‚ä½•å¤„ç† API é™æµï¼Ÿ

**A**: 
1. å®ç°æŒ‡æ•°é€€é¿é‡è¯•
2. ä½¿ç”¨å¤šä¸ªæä¾›å•†è½®æ¢
3. å®ç°è¯·æ±‚é˜Ÿåˆ—
4. ç¼“å­˜é‡å¤è¯·æ±‚

---

## ä¸ƒã€å‚è€ƒèµ„æº

### 7.1 å®˜æ–¹æ–‡æ¡£
- LiteLLM: https://docs.litellm.ai/
- OpenRouter: https://openrouter.ai/docs
- Groq: https://console.groq.com/docs
- NVIDIA NIM: https://build.nvidia.com/docs

### 7.2 å‚è€ƒé¡¹ç›®
- TrendRadar: https://github.com/sansan0/TrendRadar
- Free LLM API Resources: https://github.com/cheahjs/free-llm-api-resources
- LiteLLM: https://github.com/BerriAI/litellm

### 7.3 ç›¸å…³æ–‡æ¡£
- [çƒ­ç‚¹ç›‘æ§å€Ÿé‰´æ–‡æ¡£](./hot-topics-reference.md)
- [çƒ­ç‚¹ç›‘æ§å¼€å‘è·¯çº¿å›¾](./hot-topics-roadmap.md)

---

## å…«ã€æ›´æ–°æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | æ›´æ–°å†…å®¹ |
|------|------|----------|
| 2026-02-20 | v1.0 | åˆå§‹ç‰ˆæœ¬ï¼Œæ•´åˆå…è´¹ AI èµ„æºå’Œ LiteLLM æ–¹æ¡ˆ |

---

**æ–‡æ¡£ç»´æŠ¤**ï¼šå¼€å‘å›¢é˜Ÿ
**æœ€åæ›´æ–°**ï¼š2026-02-20
**ä¸‹æ¬¡æ›´æ–°**ï¼šæ ¹æ®å¼€å‘è¿›åº¦æ›´æ–°"å¼€å‘è¿›åº¦è®°å½•"éƒ¨åˆ†
